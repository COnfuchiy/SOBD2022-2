{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b495c4f1-e7b2-4495-b10e-e7cbaff3f6fd",
   "metadata": {},
   "source": [
    "Лабораторная работа №2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba7c537-bc1c-425b-9a9d-79d4da95a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+------+----+-------------+-------------+---------+------------+-----------+\n",
      "|           id|price| miles|year|         make|        model|body_type|transmission|engine_size|\n",
      "+-------------+-----+------+----+-------------+-------------+---------+------------+-----------+\n",
      "|38b2f52e-8f5d|20998|115879|2015|    Chevrolet|Express Cargo|Cargo Van|   Automatic|        4.8|\n",
      "|97ba4955-ccf0|27921|  7339|2018|          BMW|           i3|Hatchback|   Automatic|        0.6|\n",
      "|be1da9fd-0f34|11055| 39798|2018|   Mitsubishi|    Mirage G4|    Sedan|   Automatic|        1.2|\n",
      "|84327e45-6cb6|52997| 28568|2019|    Chevrolet|     Colorado|   Pickup|   Automatic|        2.8|\n",
      "|43847b9a-6fed| 3995|137537|2000|        Dodge|   Ram Pickup|   Pickup|      Manual|        5.2|\n",
      "|8d10256f-3be9| 6500| 74274|2010|    Chevrolet|          HHR| Mini Mpv|   Automatic|        2.2|\n",
      "|3c539e0f-3eb8|23024|131286|2016|    Chevrolet|     Colorado|   Pickup|   Automatic|        2.8|\n",
      "|dffc4e35-48e7|16995|110615|2011|Mercedes-Benz|    CLS-Class|    Coupe|   Automatic|        5.5|\n",
      "|fbdcf712-82d5| 5870|144159|2004|    Chevrolet|  TrailBlazer|      SUV|   Automatic|        4.2|\n",
      "|e9582e90-0828|27999| 60122|2008|     Maserati|  GranTurismo|    Coupe|   Automatic|        4.2|\n",
      "+-------------+-----+------+----+-------------+-------------+---------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "filename_data = 'us-dealers-used-cleaned.csv'\n",
    "csv = spark.read.csv(filename_data, inferSchema=True, header=True)\n",
    "csv = csv.withColumn('miles', csv.miles.cast(IntegerType()))\n",
    "csv.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4fd204-3fe3-476d-8fbd-9acd98101e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+-------------+-------------+---------+------------+-----+\n",
      "|price| miles|year|         make|        model|body_type|transmission|label|\n",
      "+-----+------+----+-------------+-------------+---------+------------+-----+\n",
      "|20998|115879|2015|    Chevrolet|Express Cargo|Cargo Van|   Automatic|    1|\n",
      "|27921|  7339|2018|          BMW|           i3|Hatchback|   Automatic|    0|\n",
      "|11055| 39798|2018|   Mitsubishi|    Mirage G4|    Sedan|   Automatic|    0|\n",
      "|52997| 28568|2019|    Chevrolet|     Colorado|   Pickup|   Automatic|    1|\n",
      "| 3995|137537|2000|        Dodge|   Ram Pickup|   Pickup|      Manual|    1|\n",
      "| 6500| 74274|2010|    Chevrolet|          HHR| Mini Mpv|   Automatic|    0|\n",
      "|23024|131286|2016|    Chevrolet|     Colorado|   Pickup|   Automatic|    1|\n",
      "|16995|110615|2011|Mercedes-Benz|    CLS-Class|    Coupe|   Automatic|    1|\n",
      "| 5870|144159|2004|    Chevrolet|  TrailBlazer|      SUV|   Automatic|    1|\n",
      "|27999| 60122|2008|     Maserati|  GranTurismo|    Coupe|   Automatic|    1|\n",
      "|17995|107146|2008|        Lexus|           GX|      SUV|   Automatic|    1|\n",
      "|30799| 33015|2020|    Chevrolet|Express Cargo|Cargo Van|   Automatic|    1|\n",
      "|47848|  7556|2020|    Chevrolet|     Colorado|   Pickup|   Automatic|    1|\n",
      "|40988| 69610|2014|      Porsche|      Cayenne|      SUV|   Automatic|    1|\n",
      "|35290| 12589|2020|    Chevrolet|Express Cargo|Cargo Van|   Automatic|    1|\n",
      "|15996| 31371|2018|         Ford|     Ecosport|Crossover|   Automatic|    0|\n",
      "| 5999| 73971|2004|      Mercury|     Monterey|  Minivan|   Automatic|    1|\n",
      "|16888| 35001|2012|    Chevrolet|     Colorado|   Pickup|      Manual|    1|\n",
      "|39999| 95746|2016|Mercedes-Benz|      S-Class|    Sedan|   Automatic|    1|\n",
      "|10500|141736|2008|         Ford|   Expedition|      SUV|   Automatic|    1|\n",
      "+-----+------+----+-------------+-------------+---------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv = csv.drop(csv.id).withColumn('label', when(col('engine_size') >=2.6, 1).otherwise(0))\n",
    "csv.drop(csv.engine_size).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6c0356-bf73-4d9f-9d6b-eae444416fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1951691  Testing Rows: 344505\n"
     ]
    }
   ],
   "source": [
    "splits = csv.randomSplit([0.85, 0.15])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "print(\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcaae54-6ffe-473f-84f9-00f7c5162f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCols = ['make', 'model', 'transmission','body_type'], \n",
    "                       outputCols = ['make_index', 'model_index', 'transmission_index','body_type_index'], \n",
    "                       handleInvalid = \"keep\")\n",
    "catVect = VectorAssembler(inputCols = ['make_index', 'model_index', 'transmission_index','body_type_index'], \n",
    "                          outputCol=\"features_cat\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), \n",
    "                       outputCol = \"features_index\", \n",
    "                       handleInvalid = \"keep\")\n",
    "numVect = VectorAssembler(inputCols = ['miles', 'price'], \n",
    "                          outputCol=\"features_num\", \n",
    "                          handleInvalid = \"keep\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), \n",
    "                      outputCol=\"features_norm\")\n",
    "featVect = VectorAssembler(inputCols=[\"features_index\", \"features_norm\"], \n",
    "                           outputCol=\"features\", \n",
    "                           handleInvalid = \"keep\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\", \n",
    "                            numTrees=10,  \n",
    "                            maxDepth=2, \n",
    "                            maxBins=900)\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee135e1-cd95-45e2-ad7d-ddab1d9e386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aac4c1e-1e35-424b-ae44-007e0e014cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|            features|prediction|trueLabel|\n",
      "+--------------------+----------+---------+\n",
      "|[19.0,143.0,0.0,1...|       0.0|        0|\n",
      "|[3.0,76.0,0.0,6.0...|       1.0|        1|\n",
      "|[2.0,328.0,0.0,11...|       0.0|        0|\n",
      "|[25.0,320.0,1.0,1...|       0.0|        0|\n",
      "|[4.0,11.0,0.0,1.0...|       0.0|        0|\n",
      "|[0.0,0.0,0.0,2.0,...|       1.0|        1|\n",
      "|[2.0,114.0,0.0,1....|       1.0|        1|\n",
      "|[3.0,5.0,0.0,1.0,...|       0.0|        0|\n",
      "|[2.0,318.0,1.0,5....|       0.0|        0|\n",
      "|[6.0,47.0,0.0,0.0...|       1.0|        1|\n",
      "|[16.0,595.0,1.0,2...|       0.0|        1|\n",
      "|[5.0,16.0,0.0,0.0...|       0.0|        0|\n",
      "|[15.0,140.0,0.0,4...|       0.0|        1|\n",
      "|[26.0,89.0,1.0,7....|       0.0|        0|\n",
      "|[16.0,368.0,1.0,2...|       0.0|        1|\n",
      "|[15.0,120.0,1.0,1...|       0.0|        0|\n",
      "|[2.0,555.0,1.0,1....|       0.0|        0|\n",
      "|[2.0,555.0,1.0,1....|       0.0|        0|\n",
      "|[8.0,44.0,0.0,0.0...|       1.0|        1|\n",
      "|(6,[1,5],[4.0,0.0...|       0.0|        1|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = pipelineModel.transform(test)\n",
    "pred_df.select(\"features\", \"prediction\", \"trueLabel\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af89b370-06ee-455b-af0c-4144b864f28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|           86975.0|\n",
      "|       FP|           21472.0|\n",
      "|       TN|          213037.0|\n",
      "|       FN|           23322.0|\n",
      "|Precision|0.8020046658736526|\n",
      "|   Recall|0.7885527258220986|\n",
      "|       F1|0.7952218117982666|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp = float(pred_df.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(pred_df.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(pred_df.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(pred_df.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9063980d-41fd-41b1-8350-acd46b7657b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.909421202881171\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(pred_df)\n",
    "print (\"AUR = \", aur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cab03ad-7a23-4728-8b5c-63254773ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10,15,20]).addGrid(rf.maxDepth, [1, 2, 4]).addGrid(rf.maxBins, [1000, 1200, 1400]).build()\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(metricName='areaUnderPR'), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849afcab-867a-4b3b-b5d4-c3564633af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badb73f8-552c-44b0-b0e2-5564efd12e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPrediction = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b7f96b-fc72-4945-bcf6-6713d1e80635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|           91423.0|\n",
      "|       FP|           22232.0|\n",
      "|       TN|          211818.0|\n",
      "|       FN|           19032.0|\n",
      "|Precision|0.8043904799612863|\n",
      "|   Recall|0.8276945362364764|\n",
      "|       F1|0.8158761322564811|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalculate confusion matrix\n",
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr2 = tp2 / (tp2 + fp2)\n",
    "re2 = tp2 / (tp2 + fn2)\n",
    "metrics2 = spark.createDataFrame([\n",
    " (\"TP\", tp2),\n",
    " (\"FP\", fp2),\n",
    " (\"TN\", tn2),\n",
    " (\"FN\", fn2),\n",
    " (\"Precision\", pr2),\n",
    " (\"Recall\", re2),\n",
    " (\"F1\", 2*pr2*re2/(re2+pr2))],[\"metric\", \"value\"])\n",
    "metrics2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528b25e2-f7cb-4a7c-8936-195f0dfb2b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.8663531429313123\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the Area Under ROC\n",
    "evaluator2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur2 = evaluator2.evaluate(newPrediction)\n",
    "print( \"AUR2 = \", aur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96078a3e-2b67-4560-a5ca-03127150b25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
